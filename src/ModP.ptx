//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	_Z13_uint128_modPPj

.visible .func _Z13_uint128_modPPj(
	.param .b64 _Z13_uint128_modPPj_param_0
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<34>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [_Z13_uint128_modPPj_param_0];
	ld.u32 	%r7, [%rd1+4];
	ld.u32 	%r6, [%rd1+8];
	mov.u32 	%r5, %r7;
	// inline asm
	add.cc.u32 %r5,%r5,%r6;
	// inline asm
	mov.u32 	%r24, 0;
	// inline asm
	addc.u32 %r8,%r24,%r24;
	// inline asm
	ld.u32 	%r12, [%rd1+12];
	mov.u32 	%r11, %r6;
	// inline asm
	add.cc.u32 %r11,%r11,%r12;
	// inline asm
	st.u32 	[%rd1+8], %r11;
	// inline asm
	addc.u32 %r14,%r24,%r24;
	// inline asm
	st.u32 	[%rd1+12], %r14;
	ld.u32 	%r19, [%rd1];
	mov.u32 	%r17, %r19;
	// inline asm
	sub.cc.u32 %r17,%r17,%r11;
	// inline asm
	st.u32 	[%rd1], %r17;
	mov.u32 	%r20, %r5;
	// inline asm
	subc.cc.u32 %r20,%r20,%r14;
	// inline asm
	st.u32 	[%rd1+4], %r20;
	mov.u32 	%r23, %r8;
	// inline asm
	subc.u32 %r23,%r23,%r24;
	// inline asm
	setp.ne.s32	%p1, %r23, -1;
	mov.u32 	%r33, %r23;
	@%p1 bra 	BB0_2;

	mov.u32 	%r27, -1;
	mov.u32 	%r26, %r17;
	// inline asm
	sub.cc.u32 %r26,%r26,%r27;
	// inline asm
	st.u32 	[%rd1], %r26;
	mov.u32 	%r29, %r20;
	// inline asm
	subc.u32 %r29,%r29,%r24;
	// inline asm
	st.u32 	[%rd1+4], %r29;
	mov.u32 	%r33, %r24;

BB0_2:
	ld.u64 	%rd8, [%rd1];
	setp.lt.u64	%p2, %rd8, -4294967295;
	@%p2 bra 	BB0_4;

	add.s64 	%rd8, %rd8, 4294967295;
	st.u64 	[%rd1], %rd8;

BB0_4:
	setp.ne.s32	%p3, %r33, 1;
	@%p3 bra 	BB0_6;

	add.s64 	%rd8, %rd8, 4294967295;
	st.u64 	[%rd1], %rd8;

BB0_6:
	setp.lt.u64	%p4, %rd8, -4294967295;
	@%p4 bra 	BB0_8;

	add.s64 	%rd7, %rd8, 4294967295;
	st.u64 	[%rd1], %rd7;

BB0_8:
	ret;
}

	// .globl	_Z9_mul_modPmm
.visible .func  (.param .b64 func_retval0) _Z9_mul_modPmm(
	.param .b64 _Z9_mul_modPmm_param_0,
	.param .b64 _Z9_mul_modPmm_param_1
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<82>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd4, [_Z9_mul_modPmm_param_0];
	ld.param.u64 	%rd5, [_Z9_mul_modPmm_param_1];
	cvt.u32.u64	%r23, %rd4;
	shr.u64 	%rd6, %rd4, 32;
	cvt.u32.u64	%r39, %rd6;
	shr.u64 	%rd7, %rd5, 32;
	cvt.u32.u64	%r24, %rd7;
	cvt.u32.u64	%r40, %rd5;
	// inline asm
	mul.lo.u32 %r5,%r23,%r40;
	// inline asm
	// inline asm
	mul.hi.u32 %r8,%r23,%r40;
	// inline asm
	// inline asm
	mul.lo.u32 %r11,%r39,%r24;
	// inline asm
	// inline asm
	mul.hi.u32 %r15,%r39,%r24;
	// inline asm
	// inline asm
	mul.lo.u32 %r19,%r23,%r24;
	// inline asm
	// inline asm
	mul.hi.u32 %r22,%r23,%r24;
	// inline asm
	mov.u32 	%r25, %r8;
	// inline asm
	add.cc.u32 %r25,%r25,%r19;
	// inline asm
	mov.u32 	%r28, %r11;
	// inline asm
	addc.cc.u32 %r28,%r28,%r22;
	// inline asm
	mov.u32 	%r70, 0;
	mov.u32 	%r31, %r15;
	// inline asm
	addc.u32 %r31,%r31,%r70;
	// inline asm
	mov.u32 	%r34, %r19;
	// inline asm
	mul.lo.u32 %r34,%r39,%r40;
	// inline asm
	mov.u32 	%r38, %r22;
	// inline asm
	mul.hi.u32 %r38,%r39,%r40;
	// inline asm
	mov.u32 	%r42, %r25;
	// inline asm
	add.cc.u32 %r42,%r42,%r34;
	// inline asm
	mov.u32 	%r45, %r28;
	// inline asm
	addc.cc.u32 %r45,%r45,%r38;
	// inline asm
	mov.u32 	%r48, %r31;
	// inline asm
	addc.u32 %r48,%r48,%r70;
	// inline asm
	mov.u32 	%r51, %r42;
	// inline asm
	add.cc.u32 %r51,%r51,%r45;
	// inline asm
	// inline asm
	addc.u32 %r54,%r70,%r70;
	// inline asm
	mov.u32 	%r57, %r45;
	// inline asm
	add.cc.u32 %r57,%r57,%r48;
	// inline asm
	// inline asm
	addc.u32 %r60,%r70,%r70;
	// inline asm
	mov.u32 	%r63, %r5;
	// inline asm
	sub.cc.u32 %r63,%r63,%r57;
	// inline asm
	cvt.u64.u32	%rd8, %r63;
	mov.u32 	%r66, %r51;
	// inline asm
	subc.cc.u32 %r66,%r66,%r60;
	// inline asm
	cvt.u64.u32	%rd9, %r66;
	shl.b64 	%rd10, %rd9, 32;
	or.b64  	%rd23, %rd10, %rd8;
	mov.u32 	%r69, %r54;
	// inline asm
	subc.u32 %r69,%r69,%r70;
	// inline asm
	setp.ne.s32	%p1, %r69, -1;
	mov.u32 	%r81, %r69;
	@%p1 bra 	BB1_2;

	mov.u32 	%r75, -1;
	mov.u32 	%r74, %r63;
	// inline asm
	sub.cc.u32 %r74,%r74,%r75;
	// inline asm
	cvt.u64.u32	%rd11, %r74;
	mov.u32 	%r77, %r66;
	// inline asm
	subc.u32 %r77,%r77,%r70;
	// inline asm
	cvt.u64.u32	%rd12, %r77;
	shl.b64 	%rd13, %rd12, 32;
	or.b64  	%rd23, %rd13, %rd11;
	mov.u32 	%r81, %r70;

BB1_2:
	add.s64 	%rd14, %rd23, 4294967295;
	setp.gt.u64	%p2, %rd23, -4294967296;
	selp.b64	%rd15, %rd14, %rd23, %p2;
	add.s64 	%rd16, %rd15, 4294967295;
	setp.eq.s32	%p3, %r81, 1;
	selp.b64	%rd17, %rd16, %rd15, %p3;
	setp.gt.u64	%p4, %rd17, -4294967296;
	add.s64 	%rd18, %rd17, 4294967295;
	selp.b64	%rd19, %rd18, %rd17, %p4;
	and.b64  	%rd20, %rd19, -4294967296;
	and.b64  	%rd21, %rd19, 4294967295;
	or.b64  	%rd22, %rd20, %rd21;
	st.param.b64	[func_retval0+0], %rd22;
	ret;
}


